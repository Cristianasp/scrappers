# scrappers

## a collection of python web site scrappers

This is a collection of web site scrappers that I have created for different projects.

I love using Jupyter notebook for coding, since it enables you to have a log of the code and what happens when you run it.

I strongly recommmend using Table of Contents from nbextensions. It is much more easier to arrange the code in chapters and sections, visualize, hide, etc.

### 1 Brazilian Post Offices - [Correios](http://www.correios.com.br/english)

This scrapper gets name, city and state of all post offices from the oficial post website. The result is saved in a csv file.

Written in python 3.7 
Libraries: Selenium, BeautifulSoup, Pandas

__Instalation instructions:__

To install Selenium: conda install -c conda-forge selenium 

To install BeautifulSoup: conda install -c anaconda beautifulsoup4

You also need the geckodriver driver, available [here](https://github.com/mozilla/geckodriver).

For more information on Nbextensions, visit [this page](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/index.html).


